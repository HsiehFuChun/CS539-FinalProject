{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 247
    },
    "executionInfo": {
     "elapsed": 8646,
     "status": "error",
     "timestamp": 1700326864356,
     "user": {
      "displayName": "DANIEL GHOLSON",
      "userId": "10772652804287912333"
     },
     "user_tz": 360
    },
    "id": "ACiESaD8YJ-W",
    "outputId": "8a8dd68c-5086-498c-a032-4bbf2887b723"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "5_nicolas_9.wav\n",
      "3_yweweler_14.wav\n",
      "1_lucas_5.wav\n",
      "2_george_44.wav\n",
      "4_yweweler_38.wav\n",
      "3_yweweler_28.wav\n",
      "4_yweweler_10.wav\n",
      "3_george_1.wav\n",
      "1_nicolas_15.wav\n",
      "1_jackson_42.wav\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import wave\n",
    "import pylab\n",
    "from pathlib import Path\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "INPUT_DIR = '/Users/fuchunhsieh/Desktop/Fall_2023/Comp_Sci_539/Project/free-spoken-digit-dataset-master/recordings'\n",
    "OUTPUT_DIR = '/Users/fuchunhsieh/Desktop/Fall_2023/Comp_Sci_539/Project'\n",
    "\n",
    "# list all the files and directories within a specified directory\n",
    "parent_list = os.listdir(INPUT_DIR)\n",
    "print(len(parent_list)) # 6 speakers, 10 digits, 50 recordings for each digit\n",
    "for i in range(10):\n",
    "    print(parent_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5GKQgj4nYJ-X"
   },
   "outputs": [],
   "source": [
    "# for i in range(5):\n",
    "#     # wave.open open a .wav file\n",
    "#     signal_wave  = wave.open(os.path.join(INPUT_DIR, parent_list[i]), 'r')\n",
    "#     # sample rate: the number of audio sampls taken per second\n",
    "#     # setting a low num_frames can result in shorter audio clip\n",
    "#     # set to a higher value will result in read all that are available and remains fill with zero or silence\n",
    "#     # to get frames, here single_wave.fetnframes()\n",
    "#     sample_rate = 16000\n",
    "#     # print(signal_wave.readframes(sample_rate))\n",
    "#     sig = np.frombuffer(signal_wave.readframes(sample_rate), dtype=np.int16)\n",
    "#     print(sig.shape)\n",
    "#     plt.figure(figsize=(8,4))\n",
    "#     plot_a = plt.subplot(121)\n",
    "#     plot_a.set_title(parent_list[i])\n",
    "#     plot_a.plot(sig)\n",
    "#     plot_a.set_xlabel('sample rate * time')\n",
    "#     plot_a.set_ylabel('energy')\n",
    "\n",
    "#     plot_b = plt.subplot(122)\n",
    "#     plot_b.specgram(sig, NFFT=1024, Fs=sample_rate, noverlap=900)\n",
    "#     plot_b.set_xlabel('Time')\n",
    "#     plot_b.set_ylabel('Frequency')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "LC0LR18jYJ-Y"
   },
   "outputs": [],
   "source": [
    "# def get_wav_info(wav_file):\n",
    "#     wav = wave.open(wav_file, 'r')\n",
    "#     frames = wav.readframes(-1)\n",
    "#     sound_info = np.frombuffer(frames, 'int16')\n",
    "#     frame_rate = wav.getframerate()\n",
    "#     wav.close()\n",
    "#     return sound_info, frame_rate\n",
    "# if not os.path.exists(os.path.join(OUTPUT_DIR, 'audio-images')):\n",
    "#     os.mkdir(os.path.join(OUTPUT_DIR, 'audio-images'))\n",
    "#     for filename in os.listdir(INPUT_DIR):\n",
    "#         if \"wav\" in filename:\n",
    "#             file_path = os.path.join(INPUT_DIR, filename)\n",
    "#             file_stem = Path(file_path).stem\n",
    "#             target_dir = f'class_{file_stem[0]}'\n",
    "#             dist_dir = os.path.join(OUTPUT_DIR, 'audio-images', target_dir)\n",
    "#             file_dist_path = os.path.join(dist_dir, file_stem)\n",
    "#             if not os.path.exists(dist_dir):\n",
    "#                 os.makedirs(dist_dir)\n",
    "#             if not os.path.exists(file_dist_path + '.png'):\n",
    "#                 file_stem = Path(file_path).stem\n",
    "#                 sound_info, frame_rate = get_wav_info(file_path)\n",
    "#                 pylab.specgram(sound_info, Fs = frame_rate)\n",
    "#                 pylab.savefig(f'{file_dist_path}.png')\n",
    "#                 pylab.close()\n",
    "# path_list = os.listdir(os.path.join(OUTPUT_DIR, 'audio-images'))\n",
    "# print(\"Classes: \\n\")\n",
    "# for i in range(10):\n",
    "#     print(path_list[i])\n",
    "\n",
    "# path_list = os.listdir(os.path.join(OUTPUT_DIR, 'audio-images/class_1'))\n",
    "# print(\"\\nA few example files: \\n\")\n",
    "# for i in range(10):\n",
    "#     print(path_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RxqGtOzjYJ-Z",
    "outputId": "ee8a481c-faca-4588-efa8-e76df2f881c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 files belonging to 10 classes.\n",
      "Using 2400 files for training.\n",
      "Found 3000 files belonging to 10 classes.\n",
      "Using 600 files for validation.\n"
     ]
    }
   ],
   "source": [
    "IMAGE_HEIGHT = 64\n",
    "IMAGE_WIDTH = 64\n",
    "BATCH_SIZE = 32\n",
    "N_CHANNELS = 1\n",
    "N_CLASSES = 10\n",
    "\n",
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    batch_size = BATCH_SIZE,\n",
    "    validation_split = 0.2,\n",
    "    directory = os.path.join(OUTPUT_DIR, 'audio-images'),\n",
    "    shuffle = True,\n",
    "    color_mode = 'grayscale',\n",
    "    image_size = (IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    subset = \"training\",\n",
    "    seed = 42\n",
    ")\n",
    "\n",
    "valid_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    batch_size = BATCH_SIZE,\n",
    "    validation_split = 0.2,\n",
    "    directory = os.path.join(OUTPUT_DIR, 'audio-images'),\n",
    "    shuffle = True,\n",
    "    color_mode = 'grayscale',\n",
    "    image_size = (IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    subset = \"validation\",\n",
    "    seed = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "VXYgeCi4YJ-a"
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12,12))\n",
    "# for images, labels in train_dataset.take(1):\n",
    "#     for i in range(9):\n",
    "#         ax = plt.subplot(3, 3, i+1)\n",
    "#         plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "#         plt.title(int(labels[i]))\n",
    "#         plt.axis(\"off\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-zf-L7azYJ-b"
   },
   "outputs": [],
   "source": [
    "# def prepare(ds, augment=False):\n",
    "#     rescale = tf.keras.Sequential([tf.keras.layers.experimental.preprocessing.Rescaling(1./255)])\n",
    "#     flip_and_rotate = tf.keras.Sequential(\n",
    "#         [tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "#          tf.keras.layers.experimental.preprocessing.RandomRotation(0.2)])\n",
    "#     ds = ds.map(lambda x, y: (rescale(x, training=True), y))\n",
    "#     if augment: ds = ds.map(lambda x, y: (flip_and_rotate(x, training=True), y))\n",
    "#     return ds\n",
    "# train_dataset = prepare(train_dataset, augment=False)\n",
    "# valid_dataset = prepare(valid_dataset, augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "XLvDNyUGYJ-c",
    "outputId": "dcbe6acc-5bd6-4be8-e348-3aca8fbf6438"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 32, 32, 32)        128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 16, 16, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 16, 16, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 16, 16, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 8, 8, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 8, 8, 64)          256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 8, 8, 128)         512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 4, 4, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 4, 4, 128)         512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               524544    \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 622602 (2.38 MB)\n",
      "Trainable params: 621194 (2.37 MB)\n",
      "Non-trainable params: 1408 (5.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, N_CHANNELS)))\n",
    "model.add(tf.keras.layers.Conv2D(32, 3, strides=2, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(N_CLASSES, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "75/75 [==============================] - 3s 36ms/step - loss: 1.2843 - accuracy: 0.6021 - val_loss: 3.5396 - val_accuracy: 0.2117\n",
      "Epoch 2/10\n",
      "75/75 [==============================] - 3s 35ms/step - loss: 0.4044 - accuracy: 0.8733 - val_loss: 1.2565 - val_accuracy: 0.6133\n",
      "Epoch 3/10\n",
      "75/75 [==============================] - 3s 36ms/step - loss: 0.2347 - accuracy: 0.9371 - val_loss: 0.5752 - val_accuracy: 0.8100\n",
      "Epoch 4/10\n",
      "75/75 [==============================] - 3s 35ms/step - loss: 0.1671 - accuracy: 0.9575 - val_loss: 0.2974 - val_accuracy: 0.8833\n",
      "Epoch 5/10\n",
      "75/75 [==============================] - 3s 37ms/step - loss: 0.1181 - accuracy: 0.9708 - val_loss: 0.3619 - val_accuracy: 0.8783\n",
      "Epoch 6/10\n",
      "75/75 [==============================] - 3s 39ms/step - loss: 0.1003 - accuracy: 0.9750 - val_loss: 0.2218 - val_accuracy: 0.9350\n",
      "Epoch 7/10\n",
      "75/75 [==============================] - 3s 36ms/step - loss: 0.0776 - accuracy: 0.9792 - val_loss: 0.2930 - val_accuracy: 0.9217\n",
      "Epoch 8/10\n",
      "75/75 [==============================] - 3s 36ms/step - loss: 0.0633 - accuracy: 0.9854 - val_loss: 1.4984 - val_accuracy: 0.6750\n",
      "Epoch 9/10\n",
      "75/75 [==============================] - 3s 38ms/step - loss: 0.0498 - accuracy: 0.9879 - val_loss: 0.1772 - val_accuracy: 0.9467\n",
      "Epoch 10/10\n",
      "75/75 [==============================] - 3s 39ms/step - loss: 0.0412 - accuracy: 0.9921 - val_loss: 0.1720 - val_accuracy: 0.9500\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=10, validation_data=valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "J7bh_MDdYJ-d"
   },
   "outputs": [],
   "source": [
    "# model = tf.keras.models.Sequential()\n",
    "# model.add(tf.keras.layers.Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, N_CHANNELS)))\n",
    "# model.add(tf.keras.layers.Conv2D(32, 3, strides=2, padding='same', activation='relu'))\n",
    "# model.add(tf.keras.layers.BatchNormalization())\n",
    "# model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(tf.keras.layers.BatchNormalization())\n",
    "# model.add(tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'))\n",
    "# model.add(tf.keras.layers.BatchNormalization())\n",
    "# model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(tf.keras.layers.BatchNormalization())\n",
    "# model.add(tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'))\n",
    "# model.add(tf.keras.layers.BatchNormalization())\n",
    "# model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(tf.keras.layers.BatchNormalization())\n",
    "# model.add(tf.keras.layers.Flatten())\n",
    "# model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "# model.add(tf.keras.layers.BatchNormalization())\n",
    "# model.add(tf.keras.layers.Dropout(0.5))\n",
    "# model.add(tf.keras.layers.Dense(N_CLASSES, activation='softmax'))\n",
    "\n",
    "# # Compile model\n",
    "# model.compile(\n",
    "#     loss='sparse_categorical_crossentropy',\n",
    "#     optimizer=tf.keras.optimizers.RMSprop(),\n",
    "#     metrics=['accuracy'],\n",
    "# )\n",
    "\n",
    "# # Train model for 10 epochs, capture the history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "_av8le93YJ-e",
    "outputId": "cbc8e652-a2d2-4254-f4b1-6261f3c8c238"
   },
   "outputs": [],
   "source": [
    "# # Plot the loss curves for training and validation.\n",
    "# history_dict = history.history\n",
    "# loss_values = history_dict['loss']\n",
    "# val_loss_values = history_dict['val_loss']\n",
    "# epochs = range(1, len(loss_values)+1)\n",
    "\n",
    "# plt.figure(figsize=(8,6))\n",
    "# plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "# plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "# plt.title('Training and validation loss')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "3eIksM-aYJ-f",
    "outputId": "6aaf1b95-daee-40aa-b595-6ae2588faa2a"
   },
   "outputs": [],
   "source": [
    "# # Plot the accuracy curves for training and validation.\n",
    "# acc_values = history_dict['accuracy']\n",
    "# val_acc_values = history_dict['val_accuracy']\n",
    "# epochs = range(1, len(acc_values)+1)\n",
    "\n",
    "# plt.figure(figsize=(8,6))\n",
    "# plt.plot(epochs, acc_values, 'bo', label='Training accuracy')\n",
    "# plt.plot(epochs, val_acc_values, 'b', label='Validation accuracy')\n",
    "# plt.title('Training and validation accuracy')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "5Nld1pXCYJ-g",
    "outputId": "d4790621-9713-42d7-d8f1-6d6e3313fd84"
   },
   "outputs": [],
   "source": [
    "# # Compute the final loss and accuracy\n",
    "# final_loss, final_acc = model.evaluate(valid_dataset, verbose=0)\n",
    "# print(\"Final loss: {0:.6f}, final accuracy: {1:.6f}\".format(final_loss, final_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "APZLpfU9YJ-i",
    "outputId": "ab717f7c-e121-4bee-8451-62c4abd408f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 32, 32, 32)        128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 16, 16, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 16, 16, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 16, 16, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 8, 8, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 8, 8, 64)          256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 8, 8, 128)         512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 4, 4, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 4, 4, 128)         512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               524544    \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 622602 (2.38 MB)\n",
      "Trainable params: 621194 (2.37 MB)\n",
      "Non-trainable params: 1408 (5.50 KB)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "H4Y5vdN2YJ-i"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.900548000000015 19 batches\n",
      "Average time per batch:  0.20529200000000078\n",
      "Final loss: 0.172011, final accuracy: 0.950000\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Start the timer.\n",
    "t0 = time.process_time()\n",
    "\n",
    "final_loss, final_acc = model.evaluate(valid_dataset, verbose=0)\n",
    "\n",
    "# Stop the timer.0\n",
    "t1 = time.process_time()\n",
    "\n",
    "print((t1-t0), len(valid_dataset), 'batches')\n",
    "avg_time = (t1 - t0) / len(valid_dataset)\n",
    "print(\"Average time per batch: \", avg_time)\n",
    "print(\"Final loss: {0:.6f}, final accuracy: {1:.6f}\".format(final_loss, final_acc))\n",
    "\n",
    "# penalty = ... # whatever, we'll find this out later.\n",
    "# adjusted_acc = final_acc / (1 + penalty * avg_time)\n",
    "\n",
    "# print(\"Time adjusted final accuracy: {1:.6f}\".format(adjusted_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
